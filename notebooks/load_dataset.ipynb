{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalseg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, IntSlider\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/mnt/c/Users/Ali/Documents/datasets/All-GT'\n",
    "evalseg.reload()\n",
    "@interact\n",
    "def select_dataset(dataset_name=os.listdir(root)):\n",
    "    dataset=evalseg.io.NibDataset(f'{root}/{dataset_name}')\n",
    "    @interact\n",
    "    def select_case(case=dataset.get_available_ids()):\n",
    "        gt,gt_voxel_size=dataset.get_groundtruth(case)\n",
    "        ct,ct_voxel_size=dataset.get_CT(case)\n",
    "        if ct is None: ct,ct_voxel_size=gt,gt_voxel_size \n",
    "        assert all(ct_voxel_size==gt_voxel_size)\n",
    "        gtmax=(gt.sum(axis=2).sum(axis=1).argmax(),gt.sum(axis=2).sum(axis=0).argmax(),gt.sum(axis=1).sum(axis=0).argmax())              \n",
    "        evalseg.ui.ortho_slicer(ct, {'gt':gt}, gtmax, spacing=gt_voxel_size)\n",
    "        @interact\n",
    "        def select_method(method=dataset.get_prediction_methods()):\n",
    "            pred,pred_voxel_size=dataset.get_prediction(method,case)\n",
    "            assert all(pred_voxel_size==gt_voxel_size)\n",
    "            evalseg.ui.ortho_slicer(ct, {method:pred}, gtmax, spacing=gt_voxel_size)\n",
    "        \n",
    "#         data={k:dataset.get_prediction(k,case) for k in dataset.get_prediction_methods()}\n",
    "#         data={files_inv[k]:v for k,v in eval_seg.common.parallel_runner(_load,list(files.values()))}\n",
    "        \n",
    "#         evalseg.ui.ortho_slicer(ct, {'gt':gt}, gtmax, spacing=gt_voxel_size)\n",
    "    \n",
    "#         display(evalseg.io.read_nib(dataset.get_groundtruth(case)))\n",
    "#     print(dataset.dataset_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "imgR = np.random.rand(20, 40)\n",
    "imgR2 = np.random.rand(20, 40)*5\n",
    "\n",
    "img = np.stack([imgR,imgR2])\n",
    "\n",
    "fig = px.imshow(img,zmin=0,zmax=.1, facet_col=0,  facet_col_wrap=5)\n",
    "fig.update_traces(colorscale = 'blues',)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_traces(zmax=1, selector=dict(type='heatmap'))\n",
    "# fig.data[0].update(zmax=[0.1,0.1,0.1,0.1], zauto=False)\n",
    "fig.update_traces(coloraxis=None, selector=dict(type='heatmap'))\n",
    "# fig = px.imshow(img,zmin=0,zmax=.1, facet_col=0, binary_string=True, facet_col_wrap=5)\n",
    "# fig.update_traces(z=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/mnt/c/Users/Ali/Documents/datasets/All-GT'\n",
    "evalseg.reload()\n",
    "@interact\n",
    "def select_dataset(dataset_name=os.listdir(root)):\n",
    "    dataset=evalseg.io.NibDataset(f'{root}/{dataset_name}')\n",
    "    @interact\n",
    "    def select_case(case=dataset.get_available_ids()):\n",
    "        gt,gt_voxel_size=dataset.get_groundtruth(case)\n",
    "        ct,ct_voxel_size=dataset.get_CT(case)\n",
    "        if ct is None: ct,ct_voxel_size=gt,gt_voxel_size \n",
    "        assert all(ct_voxel_size==gt_voxel_size)\n",
    "        gtmax=(gt.sum(axis=2).sum(axis=1).argmax(),gt.sum(axis=2).sum(axis=0).argmax(),gt.sum(axis=1).sum(axis=0).argmax())              \n",
    "        evalseg.ui.ortho_slicer(ct, {'gt':gt}, gtmax, spacing=gt_voxel_size)\n",
    "        @interact\n",
    "        def select_method(method=dataset.get_prediction_methods()):\n",
    "            pred,pred_voxel_size=dataset.get_prediction(method,case)\n",
    "            assert all(pred_voxel_size==gt_voxel_size)\n",
    "            evalseg.ui.ortho_slicer(ct, {'gt':gt,method:pred}, gtmax, spacing=gt_voxel_size)\n",
    "        \n",
    "#         data={k:dataset.get_prediction(k,case) for k in dataset.get_prediction_methods()}\n",
    "#         data={files_inv[k]:v for k,v in eval_seg.common.parallel_runner(_load,list(files.values()))}\n",
    "        \n",
    "#         evalseg.ui.ortho_slicer(ct, {'gt':gt}, gtmax, spacing=gt_voxel_size)\n",
    "    \n",
    "#         display(evalseg.io.read_nib(dataset.get_groundtruth(case)))\n",
    "#     print(dataset.dataset_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
